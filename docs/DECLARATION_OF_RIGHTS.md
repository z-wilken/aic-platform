# THE DECLARATION OF ALGORITHMIC RIGHTS
**Established:** February 1, 2026
**Guardian:** The AI Integrity Certification (AIC)

---

## Foundational Status

This Declaration is AIC's foundational document. It is the framework from which all AIC certifications, methodologies, audit processes, and regulatory mappings derive. Every certification tier, every scoring dimension, and every regulatory alignment — whether to POPIA Section 71, the EU AI Act, or any future jurisdiction — flows from the principles established here.

These Rights are not hypothetical aspirations. They are operational requirements, enforced through AIC's audit engine and certification process.

---

## Preamble
We hold these truths to be self-evident: that all humans are endowed with certain unalienable rights, and that among these are Life, Liberty, and the pursuit of Dignity. When algorithms are deployed to govern human affairs, they must serve these rights, not erode them.

These Rights apply to **all consequential automated decision systems** — not only systems classified as "Artificial Intelligence." Credit scoring algorithms, benefits eligibility systems, insurance underwriting models, tenant screening databases, and any other automated process that makes decisions affecting human dignity is subject to this Declaration. The technology used to build the system does not determine applicability. The impact on the human being does.

This Declaration is AIC's equivalent of a constitution — the unchanging values against which all standards, certifications, and regulatory frameworks are measured. Like the Universal Declaration of Human Rights for the algorithmic age, it asserts that certain protections are non-negotiable, regardless of jurisdiction, industry, or technology.

---

## The 5 Rights of the Data Subject

### 1. The Right to Human Agency
No final decision affecting a person's legal status, freedom, or livelihood shall be made solely by a machine. A human being must bear ultimate responsibility.

### 2. The Right to Explanation
Every person has the right to know *why* an algorithmic decision was made. "Black Box" opacity is not a defense; it is a violation.

### 3. The Right to Empathy ⬅ AIC's Unique Contribution
Automated interactions must preserve human dignity. Cruelty, dismissal, and cold bureaucratic rejection by algorithms are design failures that must be remediated.

*The Right to Empathy is AIC's singular contribution to the global governance discourse. No existing standard — not ISO 42001, not the EU AI Act, not any Big 4 consulting framework — certifies the human dignity of automated interactions. AIC does. We do not merely audit whether a decision was made correctly. We audit whether the person affected was treated as a human being.*

### 4. The Right to Correction
Every system must provide a clear, accessible, and human-staffed mechanism to correct errors and appeal unjust decisions.

### 5. The Right to Truth
A person has the right to know if they are interacting with an artificial intelligence. Deception is a violation of trust.

---

## The AIC Framework

The 5 Algorithmic Rights are operationalised through AIC's three-layer framework:

```
Layer 1: The 5 Algorithmic Rights (universal, jurisdiction-agnostic)
            ↓
Layer 2: The 3-Tier Accountability Framework (maps rights to decision stakes)
            ↓
Layer 3: Regulatory Mappings (POPIA Sec 71, EU AI Act, Title VII, LGPD, etc.)
```

POPIA Section 71 is one of the most progressive automated decision-making laws in the world, and it is AIC's market entry point in South Africa. But it sits at Layer 3 — as a regulatory expression of the universal principles above it, not as their source.

This architecture ensures that AIC certifications retain their meaning regardless of which jurisdiction a client operates in or which regulation comes into force next.

---

## Our Pledge
AIC exists to enforce these rights. We verify, we audit, and we certify. We do not serve the algorithm; we serve the human it affects.
